{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df78a135-2745-4c04-ac84-52bd265a395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/envs/Base/lib/python3.11/site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/Base/lib/python3.11/site-packages (from xgboost) (1.9.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.5\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731ea0f6-6840-489c-8fa5-2cd1c45fa8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import xgboost\n",
    "from xgboost import testing as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da6fd24-883d-42da-9429-ae62c54b52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.57500\ttrain-aucpr:0.55000\n",
      "[1]\ttrain-auc:0.65000\ttrain-aucpr:0.70000\n",
      "[2]\ttrain-auc:0.72500\ttrain-aucpr:0.85000\n",
      "[3]\ttrain-auc:0.80000\ttrain-aucpr:1.00000\n",
      "[4]\ttrain-auc:0.80000\ttrain-aucpr:1.00000\n",
      "[5]\ttrain-auc:0.80000\ttrain-aucpr:1.00000\n",
      "[6]\ttrain-auc:0.80000\ttrain-aucpr:1.00000\n",
      "[7]\ttrain-auc:0.80000\ttrain-aucpr:1.00000\n",
      "[8]\ttrain-auc:0.80000\ttrain-aucpr:1.00000\n",
      "[9]\ttrain-auc:0.80000\ttrain-aucpr:1.00000\n"
     ]
    }
   ],
   "source": [
    "Xrow = np.array([1, 2, 6, 8, 11, 14, 16, 17])\n",
    "Xcol = np.array([0, 0, 1, 1,  2,  2,  3,  3])\n",
    "X = csr_matrix((np.ones(shape=8), (Xrow, Xcol)), shape=(20, 4))\n",
    "y = np.array([0.0, 1.0, 1.0, 0.0, 0.0,\n",
    "              0.0, 1.0, 0.0, 1.0, 0.0,\n",
    "              0.0, 1.0, 0.0, 0.0, 1.0,\n",
    "              0.0, 1.0, 1.0, 0.0, 0.0])\n",
    "\n",
    "group = np.array([5, 5, 5, 5], dtype=np.uint)\n",
    "dtrain = xgboost.DMatrix(X, label=y)\n",
    "dtrain.set_group(group)\n",
    "\n",
    "params = {'eta': 1, 'tree_method': 'exact',\n",
    "          'objective': 'rank:pairwise', 'eval_metric': ['auc', 'aucpr'],\n",
    "          'max_depth': 1}\n",
    "evals_result = {}\n",
    "bst = xgboost.train(params, dtrain, 10, evals=[(dtrain, 'train')],\n",
    "                    evals_result=evals_result)\n",
    "auc_rec = evals_result['train']['auc']\n",
    "assert all(p <= q for p, q in zip(auc_rec, auc_rec[1:]))\n",
    "auc_rec = evals_result['train']['aucpr']\n",
    "assert all(p <= q for p, q in zip(auc_rec, auc_rec[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75998c72-6fa8-4114-8ed0-525ad5056cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d67bd9a1-cb21-4052-8e2e-91e3cba8dd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de7ed0-5a21-4a0d-8bc9-1dd10ddd7223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "818fa2ef-62eb-4f16-87b7-38c2a0add9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [9, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m group \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Step 4: Split data into train and test sets\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Step 5: Define xgboost parameters\u001b[39;00m\n\u001b[1;32m     20\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank:pairwise\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     26\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/envs/Base/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2445\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2445\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2447\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2448\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2449\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2450\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/Base/lib/python3.11/site-packages/sklearn/utils/validation.py:433\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    432\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 433\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/envs/Base/lib/python3.11/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [9, 3]"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score, average_precision_score\n",
    "\n",
    "# Step 2: Convert data to numpy arrays and reshape\n",
    "X = np.array([[0,1,1], [1,1,0], [1,1,1]])\n",
    "Y = np.array([['a', 'b', 'c'], ['a', 'c', 'b'], ['b', 'a', 'c']])\n",
    "X = X.reshape(-1, 1)\n",
    "Y = Y.reshape(-1, 3)\n",
    "print(X)\n",
    "# Step 3: Create group array\n",
    "group = np.array([3,3,3])\n",
    "\n",
    "# Step 4: Split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Define xgboost parameters\n",
    "params = {\n",
    "'objective': 'rank:pairwise',\n",
    "'learning_rate': 0.1,\n",
    "'max_depth': 3,\n",
    "'n_estimators': 100,\n",
    "'seed': 42\n",
    "}\n",
    "\n",
    "# Step 6: Create DMatrix object from train data and group array\n",
    "dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "dtrain.set_group(group)\n",
    "\n",
    "# Step 7: Train xgboost model\n",
    "model = xgb.train(params, dtrain)\n",
    "\n",
    "# Step 8: Create DMatrix object from test data and group array\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "dtest.set_group(group)\n",
    "\n",
    "# Step 9: Predict rankings for test data\n",
    "preds = model.predict(dtest, output_margin=True)\n",
    "preds = preds.reshape(-1, 3)\n",
    "\n",
    "# Step 10: Evaluate performance using ranking metrics\n",
    "ndcg = ndcg_score(Y_test, preds)\n",
    "map = average_precision_score(Y_test.ravel(), preds.ravel())\n",
    "print(f'NDCG score: {ndcg}')\n",
    "print(f'MAP score: {map}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf140006-0a0b-4562-b1d4-2f993c40734c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3bdf15-d439-4238-b89c-2c3683e1dd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7392d6c-3caf-411c-94f6-563e1fad08bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1244332-34ad-4ad7-85dd-f8d779540f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0,1,1], [1,1,0], [1,1,1]]\n",
    "Y = [['a', 'b', 'c'], ['a', 'c', 'b'], ['b', 'a', 'c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199283f6-8ed8-4953-bc4b-cec9504ec374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "[0 1 2 0 2 1 1 0 2]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Expecting 2 dimensional numpy.ndarray, got: ', (9,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(Y_encoded)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# set up the XGBoost model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank:pairwise\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m }\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/Base/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/Base/lib/python3.11/site-packages/xgboost/core.py:743\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 743\u001b[0m handle, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_data_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnthread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[0;32m/opt/conda/envs/Base/lib/python3.11/site-packages/xgboost/data.py:966\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_uri(data, missing, feature_names, feature_types)\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data):\n\u001b[0;32m--> 966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_tuple(data):\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_tuple(data, missing, threads, feature_names, feature_types)\n",
      "File \u001b[0;32m/opt/conda/envs/Base/lib/python3.11/site-packages/xgboost/data.py:899\u001b[0m, in \u001b[0;36m_from_list\u001b[0;34m(data, missing, n_threads, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    897\u001b[0m array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n\u001b[1;32m    898\u001b[0m _check_data_shape(data)\n\u001b[0;32m--> 899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_numpy_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/Base/lib/python3.11/site-packages/xgboost/data.py:203\u001b[0m, in \u001b[0;36m_from_numpy_array\u001b[0;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize data from a 2-D numpy matrix.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting 2 dimensional numpy.ndarray, got: \u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    206\u001b[0m data, _ \u001b[38;5;241m=\u001b[39m _ensure_np_dtype(data, data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    207\u001b[0m handle \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p()\n",
      "\u001b[0;31mValueError\u001b[0m: ('Expecting 2 dimensional numpy.ndarray, got: ', (9,))"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label encode the Y data\n",
    "le = LabelEncoder()\n",
    "Y_encoded = le.fit_transform([y for y_list in Y for y in y_list])\n",
    "\n",
    "# create an XGBoost model and train it\n",
    "import xgboost as xgb\n",
    "\n",
    "# flatten the X data to a 2D array\n",
    "X_flat = [x for x_list in X for x in x_list]\n",
    "print(X_flat)\n",
    "print(Y_encoded)\n",
    "# set up the XGBoost model\n",
    "dtrain = xgb.DMatrix(X_flat, label=Y_encoded)\n",
    "params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# make predictions\n",
    "dtest = xgb.DMatrix(X_flat)\n",
    "preds = model.predict(dtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
